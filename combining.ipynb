{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7125f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35058a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read csv file\n",
    "final_df = pd.read_csv('final.csv')\n",
    "print(final_df.shape)\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6a26d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#count number of participants\n",
    "num_participants = final_df['id'].nunique()\n",
    "\n",
    "print(f'Total number of participants: {num_participants}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b010b5a",
   "metadata": {},
   "source": [
    "### Combine data for 100 participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30d2ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a DataFrame and CSV with all the accelerometer data for 100 participants\n",
    "combined_df = pd.DataFrame()\n",
    "\n",
    "unique_participant_ids = set()\n",
    "\n",
    "error_files = []\n",
    "\n",
    "max_participant_ids = 100\n",
    "\n",
    "for index, row in final_df.iterrows():\n",
    "    participant_id = row['id']\n",
    "\n",
    "    \n",
    "    file_path = row['filename']\n",
    "    \n",
    "    try:\n",
    "        temp_df = pd.read_csv(file_path, encoding='latin1')\n",
    "\n",
    "        temp_df['id'] = participant_id\n",
    "\n",
    "        combined_df = combined_df.append(temp_df, ignore_index=True)\n",
    "\n",
    "        unique_participant_ids.add(participant_id)\n",
    "        \n",
    "        print(f\"Added: {participant_id}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file {file_path}: {e}\")\n",
    "        error_files_1.append(file_path)\n",
    "        continue\n",
    "    \n",
    "    if len(unique_participant_ids) >= max_participant_ids:\n",
    "        break\n",
    "\n",
    "#print(combined_df)\n",
    "combined_df.to_csv('data1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bab9234",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combined_df = pd.read_csv('data1.csv')\n",
    "print(combined_df.shape)\n",
    "print(combined_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c1357b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combined_df = pd.read_csv('data1.csv')\n",
    "\n",
    "#count number of participants\n",
    "num_participants = data_df['id'].nunique()\n",
    "print(f'Total number of participants: {num_participants}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f945c9a",
   "metadata": {},
   "source": [
    "### Calculate mean magnitute per week for all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09741220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing DataFrame\n",
    "mean_magnitude_per_week = pd.DataFrame() \n",
    "error_files = [] \n",
    "\n",
    "for index, row in final_df.iterrows():\n",
    "    filename = row['filename']\n",
    "    current_id = row['id']\n",
    "    \n",
    "    try:\n",
    "        # Read CSV file into a DataFrame\n",
    "        df = pd.read_csv(filename)\n",
    "        \n",
    "        # Add a new column 'id' with the id from final_df\n",
    "        df['id'] = current_id\n",
    "        \n",
    "        df['x'] = pd.to_numeric(df['x'], errors='coerce')\n",
    "        df['y'] = pd.to_numeric(df['y'], errors='coerce')\n",
    "        df['z'] = pd.to_numeric(df['z'], errors='coerce')\n",
    "        # Now, calculate the combined magnitude\n",
    "        df['magnitude'] = (df['x']**2 + df['y']**2 + df['z']**2).pow(0.5)\n",
    "        \n",
    "        # Create a new column for the week\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms', errors='coerce')\n",
    "        df['week'] = df['timestamp'].dt.to_period('W')\n",
    "        # Group by 'id' and 'week' and calculate the mean magnitude\n",
    "        df_mean = df.groupby(['id', 'week'])['magnitude'].mean().reset_index()\n",
    "\n",
    "        # Append the DataFrame to mean_magnitude_per_week\n",
    "        mean_magnitude_per_week = mean_magnitude_per_week.append(df_mean, ignore_index=True)\n",
    "        print(f\"Success: {filename}\")\n",
    "              \n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file {filename}: {e}\")\n",
    "        error_files.append(filename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646d28f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_magnitude_per_week.shape)\n",
    "print(mean_magnitude_per_week.head())\n",
    "print(mean_magnitude_per_week.tail(5))\n",
    "\n",
    "#Count number of participants\n",
    "unique_participant_count = mean_magnitude_per_week['id'].nunique()\n",
    "print(\"Count of unique participant_id:\", unique_participant_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecfccf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_magnitude_per_week.to_csv('mean_magnitude_per_week.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0b4329",
   "metadata": {},
   "source": [
    "### Calculate mean magnitute per week for all the data during sleeping hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cde9c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing DataFrame\n",
    "mean_magnitude_per_week_sleeping = pd.DataFrame()  \n",
    "error_files_sleep = []  \n",
    "\n",
    "for index, row in final_df.iterrows():\n",
    "    filename = row['filename']\n",
    "    current_id = row['id']\n",
    "    \n",
    "    try:\n",
    "        # Read CSV file into a DataFrame\n",
    "        df = pd.read_csv(filename)\n",
    "        \n",
    "        # Add a new column 'id' with the id from final_df\n",
    "        df['id'] = current_id\n",
    "\n",
    "        df['x'] = pd.to_numeric(df['x'], errors='coerce')\n",
    "        df['y'] = pd.to_numeric(df['y'], errors='coerce')\n",
    "        df['z'] = pd.to_numeric(df['z'], errors='coerce')\n",
    "        # Now, calculate the combined magnitude\n",
    "        df['magnitude'] = (df['x']**2 + df['y']**2 + df['z']**2).pow(0.5)\n",
    "        \n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms', errors='coerce')\n",
    "        # Create a new column for the week\n",
    "        df['week'] = df['timestamp'].dt.to_period('W')\n",
    "        # Create a new column for the hour of the day\n",
    "        df['hour'] = df['timestamp'].dt.hour\n",
    "\n",
    "        # Filter data for sleeping hours (0 to 7)\n",
    "        df_mean_sleep = df[(df['hour'] >= 0) & (df['hour'] <= 7)]\n",
    "\n",
    "        # Group by 'id' and 'week' and calculate the mean magnitude during sleeping hours\n",
    "        df = df_mean_sleep.groupby(['id', 'week'])['magnitude'].mean().reset_index()\n",
    "\n",
    "        # Append to DataFrame\n",
    "        mean_magnitude_per_week_sleeping = mean_magnitude_per_week_sleeping.append(df, ignore_index=True)\n",
    "        print(f\"Success: {filename}\")\n",
    "              \n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file {filename}: {e}\")\n",
    "        error_files_sleep.append(filename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031e67b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_magnitude_per_week_sleeping.shape)\n",
    "print(mean_magnitude_per_week_sleeping.head())\n",
    "print(mean_magnitude_per_week_sleeping.tail(5))\n",
    "\n",
    "#Count number of participants\n",
    "unique_participant_count = mean_magnitude_per_week_sleeping['id'].nunique()\n",
    "print(\"Count of unique participant_id:\", unique_participant_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d03b4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_magnitude_per_week_sleeping.to_csv('mean_magnitude_per_week_sleeping.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
